#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from re import search, compile, IGNORECASE
from collections import defaultdict
from argparse import ArgumentParser, SUPPRESS
import os, logging, sys
from collections import Counter
from pathlib import Path
from time import time
import bart
from bart.scripts.version import __version__
from bart.scripts.kma import kma
from bart.scripts.mash import choose_scheme
from bart.scripts.ascii import bart_ascii

__author__ = "Tom Stanton"
__license__ = "MIT"
__maintainer__ = "Tom Stanton"
__email__ = "tomdstanton@gmail.com"
__status__ = "Development"

def parse_args():
    parser = ArgumentParser(add_help=False, usage="bart input.fq.gz [options] > outfile.tab")
    parser.add_argument('input', nargs='+', type=Path, help=SUPPRESS)
    parser.print_usage = parser.print_help
    options = parser.add_argument_group('--options [defaults]')
    options.add_argument('-r', type=str, choices=['pe','se','ont','int'], help='read-type (paired/single/nanopore/interleaved)')
    options.add_argument('-s', metavar='scheme', nargs='?', type=str, const='', help='force scheme, see bart-update -s')
    options.add_argument('-p', type=int, metavar='[95]', default=95, help='template percent identity cutoff')
    options.add_argument('-o', metavar='input path', nargs='?', type=str, const='', help='export alleles to fasta')
    options.add_argument('-k', '--keep', action='store_true', default=False, help='keep temporary files')
    options.add_argument('-a', '--alt', action='store_true', default=False, help='consider alternative hits when assigning ST')
    options.add_argument('-amr', metavar='90', nargs='?', type=str, const='', help='screen for AMR genes, add percid')
    options.add_argument('-l', metavar='cwd', nargs='?', type=str, const='', help='create logfile')
    options.add_argument('-t', type=int, default=4, metavar='[4]', help='number of threads')
    options.add_argument('-v', '--verbose', action='store_true', default=False, help='print allele and alt-hits if different from profile')
    options.add_argument('-vv', '--verboser', action='store_true', default=False, help='verbose with percid, coverage and depth')
    options.add_argument('-q', '--quiet', action='store_true', default=False, help='silence messages')
    options.add_argument('-h', '--help', action='help', help='show this help message and exit')
    args = parser.parse_args()
    return args


def main():
    db_path = f'{os.path.dirname(bart.__file__)}/db'
    os.makedirs(db_path, exist_ok=True)
    os.makedirs(f'{db_path}/indexes', exist_ok=True)
    os.makedirs(f'{db_path}/mapping', exist_ok=True)
    logger = logging.getLogger('root')
    logging.basicConfig(format='%(asctime)s | %(message)s', datefmt="%H:%M:%S")
    logger.setLevel(logging.DEBUG)
    args = parse_args()
    if args.quiet:
        logger.setLevel(logging.ERROR)
    if args.l is not None:
        logpath = args.l
        if logpath == '':
            logpath = f'{os.getcwd()}/bart_{str(time()).split(".")[0]}.log'
        logger.addHandler(logging.FileHandler(logpath))
    logger.info(f'this is bart {__version__} by {__author__}')
    logger.info(f'running on {sys.platform} with Python '
                f'{str(sys.version_info[:3])[1:-1].replace(", ", ".")}')

##### Check input #####
    threads = str(args.t)
    if args.t > os.cpu_count():
        logger.warning(f'number of threads exceeds available CPUs')
        threads = str(os.cpu_count())
    logger.info(f'using {threads} threads')

    suffixes = ['_R[12]\.(f(?:ast)?q(?:\.gz)?)$', '_R[12]_[0-9]+?\.(f(?:ast)?q(?:\.gz)?)$',
                '_R[12].[0-9]+?\.(f(?:ast)?q(?:\.gz)?)$', '_[12]\.(f(?:ast)?q(?:\.gz)?)$',
                '_[12]_[0-9]+?\.(f(?:ast)?q(?:\.gz)?)$', '_[12].[0-9]+?\.(f(?:ast)?q(?:\.gz)?)$',
                '\.(f(?:ast)?q(?:\.gz)?)$'] #last one is for non-paired reads

    r = compile('|'.join(suffixes), IGNORECASE)
    reads = defaultdict(list)
    for i in args.input:
        if not os.path.isfile(i):
            logger.error(f'{i} is not a valid file')
        else:
            filename = str(i)
            s = search(r, filename)
            if s:
                reads[filename.replace(s.group(0), '')].append(str(i))
            else:
                logger.error(f'{i} is not a fastq file')

    if not any(os.scandir(f'{db_path}/indexes')):
        logger.info("no indexes found, building from PubMLST")
        os.system("bart-update -p")

    start = time()

##### Loop over read-pair dict #####
    for filenames in list(reads):
        sample = os.path.basename(filenames)
        if len(reads[filenames]) > 2:
            logger.error(f'more than 2 files for {sample}: {" ".join(reads[filenames])}')
            continue

        if not args.r: readtype = ''
        else: readtype = args.r

        if len(reads[filenames]) == 2:
            if 'se' in readtype or 'ont' in readtype or 'int' in readtype:
                logger.error(f'cannot use {readtype}, 2 files found for {sample}: {" ".join(reads[filenames])}')
                continue
            else:
                readtype = 'pe'

        if len(reads[filenames]) == 1:
            if 'pe' in readtype:
                logger.error(f'cannot use {readtype}, 2 files found for {sample}: {" ".join(reads[filenames])}')
                continue
            elif not args.r: readtype = 'se'

        rtypes = {'pe': 'paired-end', 'se': 'single-end', 'int': 'interleaved', 'ont': 'nanopore'}

        logger.info(f'reads for {sample}: {" ".join(reads[filenames])}')
        logger.info(f'assuming reads are {rtypes[readtype]}')

        ##### AMR Gene Screening #####
        if args.amr is not None:
            if not 'amr' in [f.name.split('.')[0] for f in os.scandir(f'{db_path}/indexes/')]:
                logger.info("amr index not found, building from NCBI")
                os.system("bart-update -amr")
            logger.info('screening for AMR genes')
            amr_percid = args.amr
            if amr_percid == '':
                amr_percid = '90'
            kma(reads[filenames], f'/tmp/{sample}_amr', amr_percid, f'{db_path}/indexes/amr', threads, readtype)
            with open(f'/tmp/{sample}_amr.res', newline='\n') as res:
                r = res.read().splitlines()[1:] # skip header
            if len(r) == 0:  # sys.exit IF NO HITS
                logger.error('no hits found')
                continue
            else:
                logger.info(f'{len(r)} hits found')
                print('sample\tgene\tdescription\tlength\tidentity\tcoverage\tdepth')
                for line in r:
                    result = [x.strip(' ') for x in line.split('\t')]
                    print(sample + '\t' + '\t'.join([result[0].split(' ')[0]]
                                    + [result[0].split(' ')[1].replace('_', ' ')]
                                    + result[3:6] + [result[8]]))

            if not args.keep:
                logger.info(f'cleaning up files in /tmp/')
                for f in os.listdir('/tmp/'):
                    if sample in f:
                        os.remove(f'/tmp/{f}')
            else:
                logger.info(f'kept files in /tmp/')

            continue

        if args.s is not None:
            if not args.s in [f.name.split('.')[0] for f in os.scandir(f'{db_path}/mapping/')]:
                sys.exit(logger.error(f'{args.s} not a valid scheme, use bart-update -s to see valid schemes'))
            else:
                scheme = args.s

##### Choose Scheme #####
        else: scheme = choose_scheme(sample, reads, filenames, db_path)
        if not scheme: continue

##### Run mapping and parse results #####
        # [0]Template [1]Score [2]Expected [3]Template_length [4]Template_Identity
        # [5]Template_Coverage [6]Query_Identity [7]Query_Coverage [8]Depth [9]q_value
        if not scheme in [f.name.split('.')[0] for f in os.scandir(f'{db_path}/indexes/')]:
            sys.exit(logger.error(f'{scheme} index not found in {db_path}/indexes/'))
        kma(reads[filenames], f'/tmp/{sample}', str(args.p), f'{db_path}/indexes/{scheme}', threads, readtype)
        with open(f'/tmp/{sample}.res', newline='\n') as res:
        #with open('/home/tom/PycharmProjects/bart/tests/ERR5693750.res', newline='\n') as res:
            r = res.read().splitlines()[1:] # skip header
        if len(r) == 0:
            logger.error('no hits found')
            continue
        else:
            logger.info(f'{len(r)} hits found')
            res_dict, sub_hits = {}, []  # make a dictionary of kma results where allele is the key
            for line in r:
                result = [x.strip(' ') for x in line.split('\t')][:-1]  # p_value unnecessary, always the same
                allele, gene = result[0], result[0].rsplit('_', 1)[0]  # make gene name the key
                result[0] = result[0].rsplit('_', 1)[1]  # make allele number first element
                if gene in res_dict.keys():  # if the gene is already in results dict
                    if float(result[4]) > float(res_dict[gene][4]) and float(result[4]) <=100:
                        sub_hits.append('{}_{}'.format(gene, res_dict[gene][0]))
                        res_dict[gene] = result

                    elif float(result[4]) == float(res_dict[gene][4]) and float(result[4]) <=100:
                        if float(result[9]) > float(res_dict[gene][9]):
                            sub_hits.append('{}_{}'.format(gene, res_dict[gene][0]))
                            res_dict[gene] = result
                        else:
                            sub_hits.append(allele)
                    else:
                        sub_hits.append(allele)
                else:
                    res_dict[gene] = result

##### Assign profile via a range of methods #####
        with open(f'{db_path}/mapping/{scheme}.tab', newline='\n') as tab:
        #with open(f'{db_path}/mapping/Klebsiella_pneumoniae.tab', newline='\n') as tab:
            s = tab.read().splitlines()
        headers = s[0].split('\t')[1:]
        scheme_dict = {}  # make a dictionary of the scheme where ST is the key
        for line in s[1:]: # first column is ST
            v = line.split('\t')
            scheme_dict[int(v[0])] = {headers[i]: v[1:][i] for i in range(len(headers))}

        # make a list of only genes in headers
        genes = [g for g in headers if g not in ['clonal_complex', 'species', 'CC', 'Lineage']]
        exact, no_hit = [], []
        for i in genes:
            if i in list(res_dict): # check if gene in scheme was a hit in results
                if float(res_dict[i][4]) >= 100 and float(res_dict[i][5]) >= 100: # percid and coverage
                    exact.append(i) # make a list of genes with exact matches
            else:
                no_hit.append(i)
                logger.info('no hit for ' + i)
                for p in scheme_dict.keys(): # check if scheme considers missing allele
                    if scheme_dict[p][i] == '0':
                        logger.info(f'this scheme considers missing {i} alleles, setting {i} allele to 0')
                        res_dict[i] = ['0'] + ['missing'] * 10
                        exact.append(i)
                        break

        [genes.remove(gene) for gene in no_hit if gene not in exact] # remove no-hits if scheme doesn't consider 0 as allele
        not_exact = list({*exact} ^ {*res_dict.keys()}) # make a list of non-exact genes

        if len(exact) > 0:
            # Quickly filter profiles based on exact hits #
            profile_dict = dict(scheme_dict)
            for gene in exact:
                for st in list(profile_dict.keys()):
                    if scheme_dict[st][gene] != res_dict[gene][0]:
                        profile_dict.pop(st)
        else:
            profile_dict = dict(scheme_dict)
            for gene in genes:
                allele = res_dict[gene][0]
                for st in list(profile_dict.keys()):
                    if scheme_dict[st][gene] != allele:
                        profile_dict.pop(st)
            if args.alt:
                for hit in sub_hits:
                    alt_gene, alt_allele = hit.rsplit('_', 1)
                    for gene in genes:
                        allele = res_dict[gene][0]
                        if gene == alt_gene:
                            allele = alt_allele
                        for st in list(profile_dict.keys()):
                            if scheme_dict[st][gene] != allele:
                                profile_dict.pop(st)

        if len(profile_dict) != 1:
            logger.info('no exact profile match, assigning nearest')
            # Filter nearest STs from alleles
            sts, profile_dict = [], {}
            for gene in res_dict.keys():
                sts += [st for st in scheme_dict.keys() if scheme_dict[st][gene] == res_dict[gene][0]]

            if args.alt:
                for hit in sub_hits:
                    gene, allele = hit.rsplit('_', 1)
                    sts += [st for st in scheme_dict.keys() if scheme_dict[st][gene] == allele]

            for st in [k for k, v in Counter(sts).items() if v == max(Counter(sts).values())]:
                profile_dict[st] = scheme_dict[st]

##### Printing output #####

        if len(profile_dict) == 0: # just print results if no profile match
            out = f'{sample}\t{scheme}\t?'
            for gene in res_dict.keys():
                out += '\t' + f'{res_dict[gene]}({res_dict[gene][0]})'

        else:
            for k in profile_dict.keys():
                st = str(k)
                out = f'{sample}\t{scheme}\t{st}'
                for gene, allele in profile_dict[k].items(): # iterate through dictionary for each st
                    if gene in ['clonal_complex', 'species', 'CC', 'Lineage']:
                        if allele != '':
                            out += f'\t{gene}({allele})'
                    elif gene in no_hit:
                        out += f'\t{gene}({allele}-)'

                    elif gene in genes:
                        res_allele, percid, cov, depth = \
                            res_dict[gene][0], res_dict[gene][4], res_dict[gene][5], res_dict[gene][8]
                        if float(percid) != 100 or float(cov) != 100:
                            allele += '?'  # non-perfect hit
                        elif float(percid) != 100:
                            allele += '~'  # potential novel

                        if args.verbose or args.verboser:

                            if res_allele == allele.strip('?').strip('~').strip('-'):
                                if args.verboser:
                                    out += f'\t{gene}({allele}: {percid} {cov} {depth})'
                                else: out += f'\t{gene}({allele})'

                            else:
                                if args.verboser:
                                    out += f'\t{gene}({allele})[{res_allele}: {percid} {cov} {depth}]'
                                else: out += f'\t{gene}({allele})[{res_allele}]'

                            out += ','.join(i.rsplit('_', 1)[1] for i in sub_hits if gene in i)

                        else: out += f'\t{gene}({allele})'

                print(out)


        if args.o is not None:
            outfile = args.o
            if outfile == '':
                delim = '.'
                if '_' in reads[filenames][0]:
                    delim = '_'
                outfile = f'{reads[filenames][0].split(delim, 1)[0]}_alleles.fna'
            with open(f'/tmp/{sample}.fsa', newline='\n') as fna, open(outfile, 'wt') as out:
                for seq in fna.read().split('>')[1:]:
                    for k, v in res_dict.items():
                        if f'{k}_{v[0]}' in seq:
                            if k in not_exact:
                                out.write('>{}_novel\n{}'.format(k, seq.split("\n", 1)[1]))
                            else:
                                out.write('>{}_{}\n{}'.format(k, v[0], seq.split("\n", 1)[1]))
            logger.info(f'written alleles to {outfile}')

##### Cleanup #####
        if not args.keep:
            logger.info(f'cleaning up files in /tmp/')
            for f in os.listdir('/tmp/'):
                if sample in f:
                    os.remove(f'/tmp/{f}')
        else:
            logger.info(f'kept files in /tmp/')

    logger.info(f'completed in {"{:.1f}".format(time() - start)} seconds{bart_ascii()}')


if __name__ == '__main__':
    main()
